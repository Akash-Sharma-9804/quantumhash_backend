

// const pdfParse = require("pdf-parse");
// const mammoth = require("mammoth");
// const Tesseract = require("tesseract.js");
// const db = require("../config/db");
// const uploadToFTP = require("../utils/ftpUploader");

// // üß† Extract text from buffer
// const extractText = async (buffer, mimeType) => {
//   try {
//     if (mimeType === "application/pdf") {
//       return (await pdfParse(buffer)).text;
//     } else if (mimeType === "text/plain") {
//       return buffer.toString("utf8");
//     } else if (
//       mimeType === "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
//     ) {
//       return (await mammoth.extractRawText({ buffer })).value;
//     } else if (mimeType.startsWith("image")) {
//       return (await Tesseract.recognize(buffer, "eng")).data.text;
//     } else {
//       return "Unsupported file type";
//     }
//   } catch (err) {
//     console.error("‚ùå Text extraction error:", err);
//     return null;
//   }
// };

// exports.uploadFiles = async (req, res) => {
//   try {
//       const user_id = req.user?.user_id || req.body.user_id;
//       if (!user_id) {
//           return res.status(400).json({ error: "Missing user_id." });
//       }

//       const files = req.files || [];
//       const userMessage = req.body.message?.trim();
//       let { conversation_id } = req.body;
//       let finalConversationId = conversation_id;

//       // Create new conversation if not given
//       if (!conversation_id) {
//           const [convResult] = await db.query(
//               "INSERT INTO conversations (user_id, name) VALUES (?, ?)",
//               [user_id, userMessage?.slice(0, 20) || "New Conversation"]
//           );
//           finalConversationId = convResult.insertId;
//       }

//       const results = [];
//       let allText = "";

//       for (const file of files) {
//           const buffer = file.buffer;
//           const originalName = file.originalname;
//           const fileName = Date.now() + "-" + originalName;

//           console.log(`üìÑ Processing: ${originalName} | Type: ${file.mimetype}`);

//           let extractedText = "";
//           let ftpPath = "";

//           try {
//               extractedText = await extractText(buffer, file.mimetype);
//           } catch (err) {
//               console.error("‚ùå Failed to extract text:", err.message);
//           }

//           try {
//               ftpPath = await uploadToFTP(buffer, fileName);
//           } catch (err) {
//               console.error("‚ùå FTP upload failed:", err.message);
//           }

//           if (ftpPath) {
//             const fileResult = await db.query(
//               "INSERT INTO uploaded_files (user_id, file_path, extracted_text, conversation_id) VALUES (?, ?, ?, ?)",
//               [user_id, ftpPath, extractedText || "", finalConversationId]
//           );
          
//           // Log the result to check the output from the database query
//           console.log("Database Insert Result:", fileResult);
          
//           // Check if the result is an array (which is expected)
//           if (Array.isArray(fileResult) && fileResult.length > 0) {
//               // If it's an array and has results, push to results
//               results.push({
//                   file_name: originalName, // ONLY filename sent
//               });
//           } else {
//               // If it's not an array or empty, log an error
//               console.error("‚ùå Unexpected result format from DB:", fileResult);
//           }
          
          
              
//           }

//           if (extractedText) {
//               allText += `\n---\n${extractedText}`;
//           }
//       }

//       // Prepare response
//       const response = {
//           success: true,
//           conversation_id: finalConversationId,
//       };

//       if (files.length > 0) {
//           response.files = results;
//           response.extracted_summary = allText
//               ? `Here's what I understood from your files:\n${allText.slice(0, 1000)}${allText.length > 1000 ? "..." : ""}`
//               : "I received your files, but couldn't extract readable text from them.";
//       }

//       return res.status(201).json(response);

//   } catch (err) {
//       console.error("‚ùå uploadFiles crashed:", err);
//       return res.status(500).json({
//           error: "Failed to upload files",
//           details: err.message,
//       });
//   }
// };


const pdf = require("pdf-parse");
const mammoth = require("mammoth");
const Tesseract = require("tesseract.js");
const { fromPath } = require("pdf2pic");
const tmp = require("tmp-promise");
const fs = require("fs").promises;
const { PDFDocument } = require("pdf-lib");
const db = require("../config/db");
const uploadToFTP = require("../utils/ftpUploader");

 
 
 
 

const extractText = async (buffer, mimeType) => {
  try {
    if (mimeType === "application/pdf") {
      const parsed = await pdf(buffer);
      const rawText = parsed.text?.trim() || "";
      const totalPages = parsed.numpages;
      console.log("üìö Total PDF pages:", totalPages);
      console.log("üìÑ Parsed PDF text length:", rawText.length);

      const useOCR = !rawText || rawText.length < 100;

      if (useOCR) {
        console.log("üîÅ Falling back to OCR for all pages...");
        const tmpFile = await tmp.file({ postfix: ".pdf" });
        await fs.writeFile(tmpFile.path, buffer);

        const converter = fromPath(tmpFile.path, {
          density: 150,
          format: "png",
          width: 1200,
          height: 1600,
          savePath: "/tmp",
        });

        const fullTextByPage = [];

        for (let i = 1; i <= totalPages; i++) {
          try {
            const pageImage = await converter(i);
            const { data } = await Tesseract.recognize(pageImage.path, "eng", {
              logger: m => console.log(`üìÑ OCR Progress (Page ${i}):`, m.progress),
            });
            const pageText = data.text?.trim() || "[No text found]";
            fullTextByPage.push(`\n--- Page ${i} ---\n${pageText}`);
          } catch (err) {
            console.error(`‚ùå OCR failed on page ${i}:`, err.message);
            fullTextByPage.push(`\n--- Page ${i} ---\n[OCR failed: ${err.message}]`);
          }
        }

        await tmpFile.cleanup?.();
        return fullTextByPage.join("\n").trim();
      }

      // üîç Attempt to simulate page breaks (pdf-parse doesn't do this perfectly)
      const lines = rawText.split("\n");
      const approxLinesPerPage = Math.ceil(lines.length / totalPages);
      const fullTextByPage = [];

      for (let i = 0; i < totalPages; i++) {
        const pageLines = lines.slice(i * approxLinesPerPage, (i + 1) * approxLinesPerPage);
        fullTextByPage.push(`\n--- Page ${i + 1} ---\n${pageLines.join("\n")}`);
      }

      const finalText = fullTextByPage.join("\n").trim();
      console.log("‚úÖ Final extracted length:", finalText.length);
      return finalText;
    }

    if (mimeType === "application/vnd.openxmlformats-officedocument.wordprocessingml.document") {
      const result = await mammoth.extractRawText({ buffer });
      return result.value.trim();
    }

    if (mimeType === "text/plain") {
      return buffer.toString("utf8").trim();
    }

    if (mimeType.startsWith("image")) {
      const { data } = await Tesseract.recognize(buffer, "eng", {
        logger: m => console.log("üñºÔ∏è OCR progress:", m.progress),
      });
      return data.text?.trim() || "[No text extracted from image]";
    }

    return "Unsupported file type.";
  } catch (err) {
    console.error("‚ùå extractText crashed:", err.message);
    return "[Extraction failed]";
  }
};






// üì• File upload handler
exports.uploadFiles = async (req, res) => {
    try {
        const user_id = req.user?.user_id || req.body.user_id;
        if (!user_id) {
            return res.status(400).json({ error: "Missing user_id." });
        }

        const files = req.files || [];
        const userMessage = req.body.message?.trim();
        let { conversation_id } = req.body;
        let finalConversationId = conversation_id;

        if (!conversation_id) {
            const [convResult] = await db.query(
                "INSERT INTO conversations (user_id, name) VALUES (?, ?)",
                [user_id, userMessage?.slice(0, 20) || "New Conversation"]
            );
            finalConversationId = convResult.insertId;
        }

        const results = [];
        let allText = "";

        for (const file of files) {
            const buffer = file.buffer;
            const originalName = file.originalname;
            const fileName = Date.now() + "-" + originalName;

            console.log(`üìÑ Processing: ${originalName} | Type: ${file.mimetype}`);

            let extractedText = "";
            let ftpPath = "";

            try {
                extractedText = await extractText(buffer, file.mimetype);
                console.log("üßæ Final extracted text preview:\n", extractedText?.slice(0, 500));
            } catch (err) {
                console.error("‚ùå Text extraction failed:", err.message);
            }

            try {
                ftpPath = await uploadToFTP(buffer, fileName);
            } catch (err) {
                console.error("‚ùå FTP upload failed:", err.message);
            }

            if (ftpPath) {
                try {
                    await db.query(
                        "INSERT INTO uploaded_files (user_id, file_path, extracted_text, conversation_id) VALUES (?, ?, ?, ?)",
                        [user_id, ftpPath, extractedText || "", finalConversationId]
                    );
                    results.push({ file_name: originalName });
                } catch (err) {
                    console.error("‚ùå DB insert failed:", err.message);
                }
            }

            if (extractedText) {
                allText += `\n---\n${extractedText}`;
            }
        }

        const response = {
            success: true,
            conversation_id: finalConversationId,
            files: results,
            extracted_summary: allText
                ? `Here's what I understood from your files:\n${allText.slice(0, 1000)}${allText.length > 1000 ? "..." : ""}`
                : "I received your files, but couldn't extract readable text from them.",
            extracted_summary_raw: allText,
        };

        return res.status(201).json(response);

    } catch (err) {
        console.error("‚ùå uploadFiles crashed:", err);
        return res.status(500).json({
            error: "Failed to upload files",
            details: err.message,
        });
    }
};
